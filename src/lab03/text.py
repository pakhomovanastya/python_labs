<<<<<<< HEAD
import re
def normalize(text: str, *, casefold: bool = True, yo2e: bool = True) -> str:
    if casefold:
        text = text.casefold() 
        '''casefold() Ð»ÑƒÑ‡ÑˆÐµ Ñ‡ÐµÐ¼ lower(), Ð¿Ð¾Ñ‚Ð¾Ð¼Ñƒ Ñ‡Ñ‚Ð¾ ÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ð¾ Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚ Ñ Ñ€Ð°Ð·Ð½Ñ‹Ð¼Ð¸ ÑÐ·Ñ‹ÐºÐ°Ð¼Ð¸'''
    if yo2e:
        text = text.replace('Ð', 'Ð•')
        text = text.replace('Ñ‘', 'Ðµ')
    text = text.strip()
    text = re.sub(r'\\[trnwfdv]', ' ', text)
    '''ÐÐ°Ñ…Ð¾Ð´Ð¸Ñ‚ ÑÐ¸Ð¼Ð²Ð¾Ð»Ñ‹ Ñ‚Ð¸Ð¿Ð° \t, \n, \r Ð¸ Ð·Ð°Ð¼ÐµÐ½ÑÐµÑ‚ Ð¸Ñ… Ð½Ð° Ð¾Ð±Ñ‹Ñ‡Ð½Ñ‹Ðµ Ð¿Ñ€Ð¾Ð±ÐµÐ»Ñ‹.
    Ð­Ñ‚Ð¸ ÑÐ¸Ð¼Ð²Ð¾Ð»Ñ‹ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÑŽÑ‚ÑÑ Ð´Ð»Ñ Ð¿ÐµÑ€ÐµÐ½Ð¾ÑÐ¾Ð² ÑÑ‚Ñ€Ð¾Ðº, Ñ‚Ð°Ð±ÑƒÐ»ÑÑ†Ð¸Ð¸ Ð¸ Ñ‚.Ð´.'''
    text = ' '.join(text.split())
    return text

def tokenize(text: str) -> list[str]:
    text_1 = text.replace(',', ' ').replace('.', ' ').replace(':', ' ').replace(';', ' ').replace('!', ' ').replace('?', ' ')
    text_1 = text_1.split()
    b = []
    for i in text_1:
        if i[0].isdigit() == 0 and i[0].isalpha() == 0: 
            pass ## Ð•ÑÐ»Ð¸ Ð¿ÐµÑ€Ð²Ñ‹Ð¹ ÑÐ¸Ð¼Ð²Ð¾Ð» "Ð¿Ð»Ð¾Ñ…Ð¾Ð¹" (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€, ÑÐ¼Ð°Ð¹Ð»Ð¸Ðº), ÑÐ»Ð¾Ð²Ð¾ Ð¿Ñ€Ð¾Ð¿ÑƒÑÐºÐ°ÐµÑ‚ÑÑ
        # i[0]== 0 Ñ‚Ðº Ð¼Ñ‹ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÑÐ²Ð»ÑÐµÑ‚ÑŒÑÑ Ð»Ð¸ i Ñ‡Ð¸ÑÐ»Ð¾Ð¼\Ð±ÑƒÐºÐ²Ð¾Ð¹,
        # 0 Ð¿Ñ€Ð¾Ð²ÐµÑ€ÑÐµÑ‚ Ð¿Ñ€Ð°Ð²Ð´Ð° ÑÑ‚Ð¾ Ð¸Ð»Ð¸ Ð½ÐµÑ‚. Ð•ÑÐ»Ð¸ fals, Ñ‚Ð¾ Ð½Ðµ Ð´Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ 
        # Ð² ÑÐ¿Ð¸ÑÐ¾Ðº. pass Ð¿Ñ€Ð¾Ð¿ÑƒÑÐºÐ°ÐµÑ‚ i Ð¸ Ð½Ðµ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÑÐµÑ‚ if
        else:
            b.append(i)
    return b

def count_freq(tokens: list[str]) -> dict[str, int]:
    unic_tokens = list(set(tokens))
    '''Ð¿Ñ€ÐµÐ²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ ÑÑ‚Ð¾ Ð¼Ð½Ð¾Ð¶ÐµÑÑ‚Ð²Ð¾ Ð¾Ð±Ñ€Ð°Ñ‚Ð½Ð¾ Ð² ÑÐ¿Ð¸ÑÐ¾Ðº,
    Ð´Ð°Ð»ÐµÐµ Ð¿Ð¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ ÑÐ¿Ð¸ÑÐ¾Ðº Ð²ÑÐµÑ… ÑƒÐ½Ð¸ÐºÐ°Ð»ÑŒÐ½Ñ‹Ñ… ÑÐ»Ð¾Ð²'''
    count_tokens = []
    for i in unic_tokens:
        count_tokens.append(tokens.count(i))
    dict_tokens = dict(zip(unic_tokens,count_tokens))
    '''"ÑÑˆÐ¸Ð²Ð°ÐµÑ‚" Ð´Ð²Ð° ÑÐ¿Ð¸ÑÐºÐ° Ð²Ð¼ÐµÑÑ‚Ðµ [("a", 3), ("b", 2), ("c", 1)]
    dict(...) - Ð¿Ñ€ÐµÐ²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ ÑÑ‚Ð¸ Ð¿Ð°Ñ€Ñ‹ Ð² ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ {"a": 3, "b": 2, "c": 1}'''
    return dict_tokens

# def top_n(freq: dict[str, int], n: int = 5) -> list[tuple[str, int]]:
#     freq = count_freq(freq)
#     new_dict = freq.items()
#     top = sorted(new_dict, key=lambda x: x[0])
#     '''Ð¼Ñ‹ ÑÐ¾Ñ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ ÑÐ¿Ð¸ÑÐ¾Ðº new_dict Ð¿Ð¾ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñƒ (x[0]) Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒÑŽ key
#     Ð² key Ð¼Ñ‹ Ð¿ÐµÑ€ÐµÐ´Ð°Ñ‘Ð¼ Ð¿Ð°Ñ€Ð¼Ð°ÐµÑ‚Ñ€ ÑÐ¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²ÐºÐ°'''
#     ans = sorted(top, key=lambda x: -x[1])[:n]
#     return ans

def top_n(freq: dict[str, int], n: int = 5) -> list[tuple[str, int]]:
    freq = count_freq(freq)
    top = sorted(list(freq.items()), key=lambda x: (-x[1], x[0])) [:n] # items Ð²Ñ‹Ð²Ð¾Ð´Ð¸Ñ‚ ÑÐ¿Ð¸ÑÐ¾Ðº ÐºÐ¾Ñ€Ñ‚ÐµÐ¶ÐµÐ¹ Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ (ÐºÐ»ÑŽÑ‡, Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ) 
    '''key=lambda x: x[0] Ð¿Ñ€Ð°Ð²Ð¸Ð»Ð¾ ÑÐ¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²ÐºÐ¸ Ð¸ [:n] ÑÑ€ÐµÐ·, Ð±ÐµÑ€ÐµÐ¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¿ÐµÑ€Ð²Ñ‹Ðµ n ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚Ð¾Ð²
    lambda x - ÑÐ¾Ð·Ð´Ð°ÐµÐ¼ Ñ„ÑƒÐ½ÐºÑ†Ð¸ÑŽ
    (-x[1], x[0]) - ÐºÐ¾Ñ€Ñ‚ÐµÐ¶ Ð¸Ð· Ð´Ð²ÑƒÑ… ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚Ð¾Ð²:
    -x[1] - Ð¼Ð¸Ð½ÑƒÑ Ð¿ÐµÑ€ÐµÐ´ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾Ð¼ (ÑÐ¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²ÐºÐ° Ð¿Ð¾ Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ñ‹)
    x[0] - ÑÐ»Ð¾Ð²Ð¾ (ÑÐ¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²ÐºÐ° Ð¿Ð¾ Ð°Ð»Ñ„Ð°Ð²Ð¸Ñ‚Ð°)
    Ð´Ð°Ð»ÐµÐµ ÑÐ¾Ñ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ ÑÐ»Ð¾Ð²Ð° Ð¿Ð¾ Ð²Ð¾Ð·Ñ€Ð°ÑÑ‚Ð°Ð½Ð¸ÑŽ'''
    return top

test_case_normalize = ['ÐŸÑ€Ð˜Ð²Ð•Ñ‚\nÐœÐ˜Ñ€\t', 'Ñ‘Ð¶Ð¸Ðº, ÐÐ»ÐºÐ°', 'Hello\r\nWorld', '  Ð´Ð²Ð¾Ð¹Ð½Ñ‹Ðµ   Ð¿Ñ€Ð¾Ð±ÐµÐ»Ñ‹  ']
test_case_tokenize = ['Ð¿Ñ€Ð¸Ð²ÐµÑ‚ Ð¼Ð¸Ñ€', 'hello,world!!!', 'Ð¿Ð¾-Ð½Ð°ÑÑ‚Ð¾ÑÑ‰ÐµÐ¼Ñƒ ÐºÑ€ÑƒÑ‚Ð¾', '2025 Ð³Ð¾Ð´', 'emoji ðŸ˜€ Ð½Ðµ ÑÐ»Ð¾Ð²Ð¾']
test_case_count_freq =[["a","b","a","c","b","a"]]


for i in test_case_normalize:
    print(normalize(i))

for n in test_case_tokenize:
    print(tokenize(n))

for n in test_case_count_freq:
=======
import re
def normalize(text: str, *, casefold: bool = True, yo2e: bool = True) -> str:
    if casefold:
        text = text.casefold() 
        '''casefold() Ð»ÑƒÑ‡ÑˆÐµ Ñ‡ÐµÐ¼ lower(), Ð¿Ð¾Ñ‚Ð¾Ð¼Ñƒ Ñ‡Ñ‚Ð¾ ÐºÐ¾Ñ€Ñ€ÐµÐºÑ‚Ð½Ð¾ Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚ Ñ Ñ€Ð°Ð·Ð½Ñ‹Ð¼Ð¸ ÑÐ·Ñ‹ÐºÐ°Ð¼Ð¸'''
    if yo2e:
        text = text.replace('Ð', 'Ð•')
        text = text.replace('Ñ‘', 'Ðµ')
    text = text.strip()
    text = re.sub(r'\\[trnwfdv]', ' ', text)
    '''ÐÐ°Ñ…Ð¾Ð´Ð¸Ñ‚ ÑÐ¸Ð¼Ð²Ð¾Ð»Ñ‹ Ñ‚Ð¸Ð¿Ð° \t, \n, \r Ð¸ Ð·Ð°Ð¼ÐµÐ½ÑÐµÑ‚ Ð¸Ñ… Ð½Ð° Ð¾Ð±Ñ‹Ñ‡Ð½Ñ‹Ðµ Ð¿Ñ€Ð¾Ð±ÐµÐ»Ñ‹.
    Ð­Ñ‚Ð¸ ÑÐ¸Ð¼Ð²Ð¾Ð»Ñ‹ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÑŽÑ‚ÑÑ Ð´Ð»Ñ Ð¿ÐµÑ€ÐµÐ½Ð¾ÑÐ¾Ð² ÑÑ‚Ñ€Ð¾Ðº, Ñ‚Ð°Ð±ÑƒÐ»ÑÑ†Ð¸Ð¸ Ð¸ Ñ‚.Ð´.'''
    text = ' '.join(text.split())
    return text

def tokenize(text: str) -> list[str]:
    text_1 = text.replace(',', ' ').replace('.', ' ').replace(':', ' ').replace(';', ' ').replace('!', ' ').replace('?', ' ')
    text_1 = text_1.split()
    b = []
    for i in text_1:
        if i[0].isdigit() == 0 and i[0].isalpha() == 0: 
            pass ## Ð•ÑÐ»Ð¸ Ð¿ÐµÑ€Ð²Ñ‹Ð¹ ÑÐ¸Ð¼Ð²Ð¾Ð» "Ð¿Ð»Ð¾Ñ…Ð¾Ð¹" (Ð½Ð°Ð¿Ñ€Ð¸Ð¼ÐµÑ€, ÑÐ¼Ð°Ð¹Ð»Ð¸Ðº), ÑÐ»Ð¾Ð²Ð¾ Ð¿Ñ€Ð¾Ð¿ÑƒÑÐºÐ°ÐµÑ‚ÑÑ
        # i[0]== 0 Ñ‚Ðº Ð¼Ñ‹ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ ÑÐ²Ð»ÑÐµÑ‚ÑŒÑÑ Ð»Ð¸ i Ñ‡Ð¸ÑÐ»Ð¾Ð¼\Ð±ÑƒÐºÐ²Ð¾Ð¹,
        # 0 Ð¿Ñ€Ð¾Ð²ÐµÑ€ÑÐµÑ‚ Ð¿Ñ€Ð°Ð²Ð´Ð° ÑÑ‚Ð¾ Ð¸Ð»Ð¸ Ð½ÐµÑ‚. Ð•ÑÐ»Ð¸ fals, Ñ‚Ð¾ Ð½Ðµ Ð´Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ 
        # Ð² ÑÐ¿Ð¸ÑÐ¾Ðº. pass Ð¿Ñ€Ð¾Ð¿ÑƒÑÐºÐ°ÐµÑ‚ i Ð¸ Ð½Ðµ Ð²Ñ‹Ð¿Ð¾Ð»Ð½ÑÐµÑ‚ if
        else:
            b.append(i)
    return b

def count_freq(tokens: list[str]) -> dict[str, int]:
    unic_tokens = list(set(tokens))
    '''Ð¿Ñ€ÐµÐ²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ ÑÑ‚Ð¾ Ð¼Ð½Ð¾Ð¶ÐµÑÑ‚Ð²Ð¾ Ð¾Ð±Ñ€Ð°Ñ‚Ð½Ð¾ Ð² ÑÐ¿Ð¸ÑÐ¾Ðº,
    Ð´Ð°Ð»ÐµÐµ Ð¿Ð¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ ÑÐ¿Ð¸ÑÐ¾Ðº Ð²ÑÐµÑ… ÑƒÐ½Ð¸ÐºÐ°Ð»ÑŒÐ½Ñ‹Ñ… ÑÐ»Ð¾Ð²'''
    count_tokens = []
    for i in unic_tokens:
        count_tokens.append(tokens.count(i))
    dict_tokens = dict(zip(unic_tokens,count_tokens))
    '''"ÑÑˆÐ¸Ð²Ð°ÐµÑ‚" Ð´Ð²Ð° ÑÐ¿Ð¸ÑÐºÐ° Ð²Ð¼ÐµÑÑ‚Ðµ [("a", 3), ("b", 2), ("c", 1)]
    dict(...) - Ð¿Ñ€ÐµÐ²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ ÑÑ‚Ð¸ Ð¿Ð°Ñ€Ñ‹ Ð² ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ {"a": 3, "b": 2, "c": 1}'''
    return dict_tokens

# def top_n(freq: dict[str, int], n: int = 5) -> list[tuple[str, int]]:
#     freq = count_freq(freq)
#     new_dict = freq.items()
#     top = sorted(new_dict, key=lambda x: x[0])
#     '''Ð¼Ñ‹ ÑÐ¾Ñ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ ÑÐ¿Ð¸ÑÐ¾Ðº new_dict Ð¿Ð¾ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€Ñƒ (x[0]) Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒÑŽ key
#     Ð² key Ð¼Ñ‹ Ð¿ÐµÑ€ÐµÐ´Ð°Ñ‘Ð¼ Ð¿Ð°Ñ€Ð¼Ð°ÐµÑ‚Ñ€ ÑÐ¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²ÐºÐ°'''
#     ans = sorted(top, key=lambda x: -x[1])[:n]
#     return ans

def top_n(freq: dict[str, int], n: int = 5) -> list[tuple[str, int]]:
    freq = count_freq(freq)
    top = sorted(list(freq.items()), key=lambda x: (-x[1], x[0])) [:n] # items Ð²Ñ‹Ð²Ð¾Ð´Ð¸Ñ‚ ÑÐ¿Ð¸ÑÐ¾Ðº ÐºÐ¾Ñ€Ñ‚ÐµÐ¶ÐµÐ¹ Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ (ÐºÐ»ÑŽÑ‡, Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ) 
    '''key=lambda x: x[0] Ð¿Ñ€Ð°Ð²Ð¸Ð»Ð¾ ÑÐ¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²ÐºÐ¸ Ð¸ [:n] ÑÑ€ÐµÐ·, Ð±ÐµÑ€ÐµÐ¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¿ÐµÑ€Ð²Ñ‹Ðµ n ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚Ð¾Ð²
    lambda x - ÑÐ¾Ð·Ð´Ð°ÐµÐ¼ Ñ„ÑƒÐ½ÐºÑ†Ð¸ÑŽ
    (-x[1], x[0]) - ÐºÐ¾Ñ€Ñ‚ÐµÐ¶ Ð¸Ð· Ð´Ð²ÑƒÑ… ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚Ð¾Ð²:
    -x[1] - Ð¼Ð¸Ð½ÑƒÑ Ð¿ÐµÑ€ÐµÐ´ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾Ð¼ (ÑÐ¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²ÐºÐ° Ð¿Ð¾ Ñ‡Ð°ÑÑ‚Ð¾Ñ‚Ñ‹)
    x[0] - ÑÐ»Ð¾Ð²Ð¾ (ÑÐ¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²ÐºÐ° Ð¿Ð¾ Ð°Ð»Ñ„Ð°Ð²Ð¸Ñ‚Ð°)
    Ð´Ð°Ð»ÐµÐµ ÑÐ¾Ñ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ ÑÐ»Ð¾Ð²Ð° Ð¿Ð¾ Ð²Ð¾Ð·Ñ€Ð°ÑÑ‚Ð°Ð½Ð¸ÑŽ'''
    return top

test_case_normalize = ['ÐŸÑ€Ð˜Ð²Ð•Ñ‚\nÐœÐ˜Ñ€\t', 'Ñ‘Ð¶Ð¸Ðº, ÐÐ»ÐºÐ°', 'Hello\r\nWorld', '  Ð´Ð²Ð¾Ð¹Ð½Ñ‹Ðµ   Ð¿Ñ€Ð¾Ð±ÐµÐ»Ñ‹  ']
test_case_tokenize = ['Ð¿Ñ€Ð¸Ð²ÐµÑ‚ Ð¼Ð¸Ñ€', 'hello,world!!!', 'Ð¿Ð¾-Ð½Ð°ÑÑ‚Ð¾ÑÑ‰ÐµÐ¼Ñƒ ÐºÑ€ÑƒÑ‚Ð¾', '2025 Ð³Ð¾Ð´', 'emoji ðŸ˜€ Ð½Ðµ ÑÐ»Ð¾Ð²Ð¾']
test_case_count_freq =[["a","b","a","c","b","a"]]


for i in test_case_normalize:
    print(normalize(i))

for n in test_case_tokenize:
    print(tokenize(n))

for n in test_case_count_freq:
>>>>>>> 6f9120729c91834b4d7b4de8ffbca09df66e84e7
    print(top_n(n))